{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "UGdmtsKax9eY",
    "outputId": "fa689012-a7a9-4fd6-fcc3-e0850ca94ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.6.0\n",
      "    Uninstalling accelerate-1.6.0:\n",
      "      Successfully uninstalled accelerate-1.6.0\n",
      "Successfully installed accelerate-1.7.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Collecting rank-eval\n",
      "  Downloading rank_eval-0.1.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank-eval) (2.0.2)\n",
      "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.11/dist-packages (from rank-eval) (0.60.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rank-eval) (2.2.2)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from rank-eval) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rank-eval) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54.1->rank-eval) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rank-eval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->rank-eval) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rank-eval) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->rank-eval) (1.17.0)\n",
      "Downloading rank_eval-0.1.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: rank-eval\n",
      "Successfully installed rank-eval-0.1.3\n",
      "Collecting ranx\n",
      "  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ranx) (2.0.2)\n",
      "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.11/dist-packages (from ranx) (0.60.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ranx) (2.2.2)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ranx) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ranx) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ranx) (1.15.3)\n",
      "Collecting ir-datasets (from ranx)\n",
      "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from ranx) (13.9.4)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from ranx) (3.10.18)\n",
      "Collecting lz4 (from ranx)\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting cbor2 (from ranx)\n",
      "  Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from ranx) (0.13.2)\n",
      "Collecting fastparquet (from ranx)\n",
      "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54.1->ranx) (0.43.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx) (2.10.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx) (2025.3.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ranx) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ranx) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ranx) (2025.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx) (4.13.4)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->ranx)\n",
      "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx) (5.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx) (2.32.3)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->ranx)\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->ranx)\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx)\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->ranx)\n",
      "  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->ranx)\n",
      "  Downloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->ranx)\n",
      "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx) (18.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->ranx) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->ranx) (2.19.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn->ranx) (3.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx) (4.13.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->ranx) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ranx) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx) (2025.4.26)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx)\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Downloading ranx-0.3.20-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Building wheels for collected packages: warc3-wet-clueweb09, cbor\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=0b7154d3bc1d203335ae9994b268930c4bb394483a57c3616c0a5d72f253463a\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53929 sha256=92587ec9ea32e4710cc5a308b82f7c657c2d477d474d514689acd77f8dd55a9b\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n",
      "Successfully built warc3-wet-clueweb09 cbor\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, cbor, zlib-state, unlzw3, trec-car-tools, lz4, ijson, cbor2, inscriptis, ir-datasets, fastparquet, ranx\n",
      "Successfully installed cbor-1.0.0 cbor2-5.6.5 fastparquet-2024.11.0 ijson-3.4.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n",
      "Collecting fsspec==2023.9.2\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2023.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install --upgrade accelerate\n",
    "!pip install rank-eval\n",
    "!pip install ranx\n",
    "!pip install fsspec==2023.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MHwP1evIr23",
    "outputId": "caca7950-d4f1-47a3-b9d2-a04b41cfb33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEiw7MqrBjNY"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.autonotebook import trange\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from tqdm import tqdm\n",
    "from ranx import Qrels, Run, evaluate\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkcWQJmZboDo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMzdjmmMZQ9h"
   },
   "outputs": [],
   "source": [
    "# from utils import tsv_to_dict_multiple, tsv_to_dict_unqiue, split_embedding_into_chunks\n",
    "import csv\n",
    "\n",
    "# Read the tsv file as a dictionary (each key has a single value)\n",
    "def tsv_to_dict_unqiue(file_path, keys = [0, 1]):\n",
    "    with open(file_path, mode = \"r\", encoding = \"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter= \"\\t\")\n",
    "\n",
    "        data = {}\n",
    "        for row in reader:\n",
    "            data[row[keys[0]]] = row[keys[1]]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Read the tsv file as a dictionary (each key has a multiple value)\n",
    "def tsv_to_dict_multiple(file_path, keys = [0, 2]):\n",
    "    with open(file_path, mode = \"r\", encoding = \"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter= \"\\t\")\n",
    "\n",
    "        data = {}\n",
    "        for row in reader:\n",
    "            if row[keys[0]] in data:\n",
    "                data[row[keys[0]]].append(row[keys[1]])\n",
    "            else:\n",
    "                data[row[keys[0]]] = [row[keys[1]]]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Split the embedding to k chunks\n",
    "def split_embedding_into_chunks(embeddings, k_chunks):\n",
    "    bsz, dim = embeddings.shape\n",
    "    assert dim % k_chunks == 0\n",
    "    return embeddings.view(bsz * k_chunks, dim // k_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjgiN98MmAy7"
   },
   "outputs": [],
   "source": [
    "# Optional - To clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQV6v81uEHuK",
    "outputId": "55a0b1e6-5858-4444-9f63-3da348943249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 16 04:30:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWGZx53JNcJR"
   },
   "source": [
    "### Load raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "293ab459c5bd413e8f35ec10b3d421ed",
      "ee6c3f37424442c2b0eaa01bf6efb5b2",
      "24faabb55d10494d900d8a3625fde0c2",
      "f39a47d9662a4d4abe07a280f094b5a7",
      "bde590aaf4604c6987e35c264210fea4",
      "2d680f4fb5ac499a9600c33af63b7b97",
      "b3b160f7647a4a718b943a29ecc37989",
      "5982017a8d95409691150c47d52db356",
      "64f6df30716d4812a8b5900879a2cf75",
      "515d5e1f571945d2af33794169e7e7e6",
      "562223988d1a4de2a97d87fe69351495",
      "1b1c5d554a9e450d9e3cf698391e6fa1",
      "cbc08f621c004472a2f9af3295086e2c",
      "34126021bd6d421cb3f3eec0afa1e958",
      "c39b8c749a0341589d072716ade1a22e",
      "b7c7d0ce558a47df91fed147bd380dfc",
      "d3c4653d90b7415191185dbbe371ccbd",
      "2f63de6447e84f7f9bfeac7c98f906a1",
      "9f25f72d28494d37b4ec7664bb64d224",
      "40f187e6915343d484f18a7dc52c712a",
      "8ebbb6a9010e4fef92610c005380708d",
      "e528a474e04645fd8192053141cdf6a5",
      "f72ca9bb3d7140cfbd0fe3991e639b0f",
      "bc93cf9322b54e5c84330e6e9cf6d83b",
      "ef51f360e81347c9b64eef18136351ff",
      "eb178f4578dc40aaa844788bbc1c79ff",
      "7c41a9bce7724dc895a584c0fc6bf601",
      "180ffce0843e4ddaaded2222aeda662b",
      "d8fc27082e904831804a20ca910f6aa8",
      "cffb4d78e32443078154d0a4c3015ec0",
      "7196cf136d6b4ef7a18485fe37759cd8",
      "bdb15b1024f84ab9b5223bb775229ebb",
      "54079b2a69d64e848230111e308cb14a",
      "ae2b113c8b5647028946e5180745d22a",
      "9b4e3fedcff54072ba5443c0d14f65f5",
      "1ef9ea49b2424d15b85aae69b06c5852",
      "64e9e702d48346ddba2fbf9278eed370",
      "f7de1fe488f64558b498c4f103779bea",
      "6e67397d1a8c4e1e8240663eb43dd5b0",
      "5a49b3c7ec05444ba5bedee37ada3cf3",
      "3984cb7e6ec549dd82ccd8eb6620837a",
      "ffddd421c3444105b97180ce4444d5c4",
      "e27a2140295f43f5abccb9c516233dff",
      "760ef407acf24e7a9faa37d0ca8a9035"
     ]
    },
    "id": "I3Z3-ke6Tfp7",
    "outputId": "f62a7ebb-a470-49b3-f250-3e7b972f2810"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293ab459c5bd413e8f35ec10b3d421ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1c5d554a9e450d9e3cf698391e6fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72ca9bb3d7140cfbd0fe3991e639b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2b113c8b5647028946e5180745d22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# base-model\n",
    "model_name = \"facebook/contriever-msmarco\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh8HbnuzZQ9i"
   },
   "outputs": [],
   "source": [
    "passages = tsv_to_dict_unqiue(os.path.join('/content/drive/MyDrive/685/data', \"collection.tsv\"))\n",
    "queries = tsv_to_dict_unqiue(os.path.join('/content/drive/MyDrive/685/data', \"queries.train.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training triplets (BM25 hard negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNa2oo1GF4r9"
   },
   "outputs": [],
   "source": [
    "def create_dataset(address, n_negatives=2,cache_dir='hf',sample_count=1000):\n",
    "    def train_gen():\n",
    "      with open(address,'r') as f:\n",
    "          count = 0\n",
    "          for line in f:\n",
    "              count += 1\n",
    "              if sample_count != None and count >= sample_count: return\n",
    "              data_sample = json.loads(line)\n",
    "              negatives = []\n",
    "              for neg_id in random.sample(data_sample['neg']['bm25'],n_negatives): negatives.append(passages[str(neg_id)])\n",
    "              yield {'query': queries[str(data_sample['qid'])],'positive':passages[str(random.sample(data_sample['pos'],1)[0])],'negatives':[negatives]}\n",
    "    return Dataset.from_generator(train_gen, cache_dir = cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "cd9f4fa39a9c4602bbd81148f1235180",
      "652f7b05eb6d47df88db900dcb8c8df9",
      "bc720f41c4e948dfac60f055cb89afa0",
      "15aba9589be14607bf6dca7a63a7c8de",
      "4dc92e8965184b2698482c27af83685f",
      "3216f36606be452289155fa4b2f4791a",
      "23cf924964f14ddbb5a37b43e3bf1701",
      "eebf15813a71406c82f70a2f355e9a7d",
      "e7000fadbb584f36ae6c094a7aa69475",
      "e677f8faf420453093f2d80eebdf2cf9",
      "77749fcb19554cc5a8ee64c0eb2b84cb"
     ]
    },
    "id": "ix-FZAnuGsrx",
    "outputId": "8bbf0e16-14f9-467c-bbfa-236608d87c02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9f4fa39a9c4602bbd81148f1235180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(os.path.join('/content/drive/MyDrive/685/data','msmarco-hard-negatives-bm25_1k.jsonl'), 2, 'hf',1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMfgNUYhUb1y"
   },
   "source": [
    "### Create training triplets (BERT based hard negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHghiNkTIgia"
   },
   "outputs": [],
   "source": [
    "# def create_dataset(df, n_negatives=1,cache_dir='hf',sample_count=1000):\n",
    "#     def train_gen():\n",
    "#       samp_df = df.sample(n=sample_count, random_state=42)\n",
    "#       for index, row in samp_df.iterrows():\n",
    "#             yield {'query': queries[str(int(row[2]))],'positive':passages[str(int(row[3]))],'negatives':passages[str(int(row[4]))]}\n",
    "#     return Dataset.from_generator(train_gen, cache_dir = cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTDfHtfTNNos"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join('/content/drive/MyDrive/685/data','bert_cat_ensemble_msmarcopassage_train_scores_ids.tsv'),sep='\\t',header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVrfx1cnMnsY"
   },
   "outputs": [],
   "source": [
    "# dataset = create_dataset(df, 1, 'hf',5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skRXx-oEUnDX"
   },
   "source": [
    "### Train Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqTDgBxkPNyr"
   },
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# There might be a split over\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32NhWmxaYSvK"
   },
   "source": [
    "### Custom data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77DZ0UU7YZwH"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "class CustomDataCollatorWithPadding(DataCollatorWithPadding):\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        query_texts = []\n",
    "        pos_texts = []\n",
    "        neg_texts = []\n",
    "\n",
    "        for feature in features:\n",
    "            query_texts.append(feature['query'])\n",
    "            pos_texts.append(feature['positive'])\n",
    "            if 'negatives' in feature.keys():\n",
    "                for neg_text in feature['negatives']: neg_texts.append(neg_text)\n",
    "\n",
    "        tokenized_query_texts = self.tokenizer(\n",
    "                query_texts,\n",
    "                max_length=self.max_length,\n",
    "                padding=self.padding,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                add_special_tokens=True)\n",
    "\n",
    "        tokenized_pos_texts = self.tokenizer(\n",
    "                pos_texts,\n",
    "                max_length=self.max_length,\n",
    "                padding=self.padding,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                add_special_tokens=True)\n",
    "\n",
    "        tokenized_texts = {\n",
    "            'tokenized_queries' : tokenized_query_texts,\n",
    "            'tokenized_positives' : tokenized_pos_texts,\n",
    "        }\n",
    "\n",
    "\n",
    "        if len(neg_texts) > 0:\n",
    "            tokenized_neg_texts = self.tokenizer(\n",
    "                  neg_texts,\n",
    "                  max_length=self.max_length,\n",
    "                  padding=self.padding,\n",
    "                  truncation=True,\n",
    "                  return_tensors=\"pt\",\n",
    "                  add_special_tokens=True)\n",
    "            tokenized_texts['tokenized_negatives'] = tokenized_neg_texts\n",
    "\n",
    "        return tokenized_texts\n",
    "\n",
    "custom_data_collator = CustomDataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding='longest',\n",
    "    max_length=tokenizer.model_max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjQ1TYw2Pti-",
    "outputId": "1ec4e6ed-4ff4-4fc9-d652-78cf53b71651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10])\n",
      "torch.Size([8, 119])\n",
      "torch.Size([8, 282])\n"
     ]
    }
   ],
   "source": [
    "out_train = custom_data_collator([train_dataset[i] for i in range(8)])\n",
    "print(out_train['tokenized_queries']['input_ids'].shape)\n",
    "print(out_train['tokenized_positives']['input_ids'].shape)\n",
    "print(out_train['tokenized_negatives']['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwoMdR_xNXBT",
    "outputId": "ecb9a8f1-1b82-4473-e667-8e01f804651d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n",
      "torch.Size([2, 87])\n"
     ]
    }
   ],
   "source": [
    "out_eval = custom_data_collator([eval_dataset[i] for i in range(2)])\n",
    "print(out_eval['tokenized_queries']['input_ids'].shape)\n",
    "print(out_eval['tokenized_positives']['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEC5DkMBZctk"
   },
   "source": [
    "### Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfLPDDjdZqZW"
   },
   "outputs": [],
   "source": [
    "#enter your code here\n",
    "def get_contriever_emb(model_output, attention_mask):\n",
    "    last_hidden = model_output[\"last_hidden_state\"]\n",
    "    last_hidden = last_hidden.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    emb = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "    return emb\n",
    "\n",
    "def contrastive_loss(query_embs,pos_embs,neg_embs):\n",
    "    temp = 0.05\n",
    "    query_embs = query_embs\n",
    "    similarities_pos = torch.mm(query_embs,torch.transpose(pos_embs,0,1))/temp\n",
    "    similarities = similarities_pos\n",
    "    if neg_embs != None:\n",
    "        similarities_neg = torch.mm(query_embs,torch.transpose(neg_embs,0,1))/temp\n",
    "        similarities = torch.cat((similarities_pos,similarities_neg),dim=1)\n",
    "    return F.cross_entropy(similarities,torch.arange(0,query_embs.shape[0]).to('cuda'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12zUzO2vZt-g"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Quantization module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2RPYOuTJdvw"
   },
   "outputs": [],
   "source": [
    "class Quantize(nn.Module):\n",
    "    def __init__(self, dim, n_embed, decay=0.99, eps=1e-5, random_initialization=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_embed = n_embed\n",
    "        self.decay = decay\n",
    "        self.eps = eps\n",
    "\n",
    "        # Inititalize with pretrained codebook vectors for better training\n",
    "        if random_initialization:\n",
    "          embed = torch.randn(dim, n_embed)\n",
    "        else:\n",
    "          embed = torch.load(os.path.join('/content/drive/MyDrive/685/code','codebook_vectors.pt')).T\n",
    "\n",
    "        self.register_buffer(\"embed\", embed)\n",
    "        self.register_buffer(\"cluster_size\", torch.ones(n_embed))\n",
    "        self.register_buffer(\"embed_avg\", embed.clone())\n",
    "\n",
    "    def forward(self, input,training=True):\n",
    "        flatten = input.reshape(-1, self.dim)\n",
    "        dist = (\n",
    "            flatten.pow(2).sum(1, keepdim=True)\n",
    "            - 2 * flatten @ self.embed\n",
    "            + self.embed.pow(2).sum(0, keepdim=True)\n",
    "        )\n",
    "        _, embed_ind = (-dist).max(1)\n",
    "        embed_onehot = F.one_hot(embed_ind, self.n_embed).type(flatten.dtype)\n",
    "        embed_ind = embed_ind.view(*input.shape[:-1])\n",
    "        quantize = self.embed_code(embed_ind)\n",
    "\n",
    "        if training:\n",
    "            embed_onehot_sum = embed_onehot.sum(0)\n",
    "            embed_sum = flatten.transpose(0, 1) @ embed_onehot\n",
    "\n",
    "            self.cluster_size.data.mul_(self.decay).add_(\n",
    "                embed_onehot_sum, alpha=1 - self.decay\n",
    "            )\n",
    "            self.embed_avg.data.mul_(self.decay).add_(embed_sum, alpha=1 - self.decay)\n",
    "\n",
    "            n = self.cluster_size.sum()\n",
    "            cluster_size = (self.cluster_size + self.eps) / (n + self.n_embed * self.eps) * n\n",
    "            embed_normalized = self.embed_avg / cluster_size.unsqueeze(0)\n",
    "            self.embed.data.copy_(embed_normalized)\n",
    "\n",
    "            # --- Dead code reinitialization ---\n",
    "            with torch.no_grad():\n",
    "                dead_mask = self.cluster_size < 0.1\n",
    "                num_dead = dead_mask.sum().item()\n",
    "                if num_dead > 0 and flatten.size(0) > 0:\n",
    "                    random_indices = torch.randint(0, flatten.size(0), (num_dead,))\n",
    "                    self.embed[:, dead_mask] = flatten[random_indices].t()\n",
    "                    self.embed_avg[:, dead_mask] = flatten[random_indices].t()\n",
    "                    self.cluster_size[dead_mask] = 1.0  # or a small positive value\n",
    "\n",
    "        diff = (quantize.detach() - input).pow(2).mean()\n",
    "        quantize = input + (quantize - input).detach()\n",
    "\n",
    "        return quantize, diff, embed_ind\n",
    "\n",
    "    def embed_code(self, embed_id):\n",
    "        return F.embedding(embed_id, self.embed.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Layer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEaFY2mFZQ9k"
   },
   "outputs": [],
   "source": [
    "class Sparse_Layer(nn.Module):\n",
    "    def __init__(self,d,D):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up_projection = nn.Linear(d,D)\n",
    "        nn.init.xavier_uniform_(self.up_projection.weight)\n",
    "        nn.init.zeros_(self.up_projection.bias)\n",
    "\n",
    "    def forward(self,embeds):\n",
    "        S = self.up_projection(embeds)\n",
    "        S = torch.log(1 + torch.relu(S))\n",
    "        S = torch.clamp(S, max=10)\n",
    "        return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSR_VQ - End-to-End Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-uFO5COZQ9k"
   },
   "outputs": [],
   "source": [
    "class LSR_VQ(nn.Module):\n",
    "    def __init__(self, model_name, emb_dim, num_clusters, num_chunks, d, D, config):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name,device_map='auto')\n",
    "        if config['freeze_contriver']:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.quantizer = Quantize(emb_dim,num_clusters)\n",
    "        self.sparse_layer = Sparse_Layer(d,D)\n",
    "        self.num_chunks = num_chunks\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        query_embs = self.model(**inputs['tokenized_queries'])\n",
    "        query_dense = get_contriever_emb(query_embs,inputs['tokenized_queries']['attention_mask'])\n",
    "\n",
    "        pos_embs = self.model(**inputs['tokenized_positives'])\n",
    "        pos_dense = get_contriever_emb(pos_embs,inputs['tokenized_positives']['attention_mask'])\n",
    "\n",
    "        neg_embs = self.model(**inputs['tokenized_negatives'])\n",
    "        neg_dense = get_contriever_emb(neg_embs,inputs['tokenized_negatives']['attention_mask'])\n",
    "\n",
    "        codebook_loss = 0\n",
    "\n",
    "        if self.config['use_quantization'] :\n",
    "\n",
    "            embeds_to_quantize = torch.cat([query_dense,pos_dense,neg_dense],dim=0)\n",
    "\n",
    "            embeds = split_embedding_into_chunks(embeds_to_quantize,self.num_chunks)\n",
    "\n",
    "            quantized_embs_chunks, codebook_loss, _ = self.quantizer(embeds,not self.config['freeze_vq'])\n",
    "\n",
    "            bsz_k, dim_chunk = quantized_embs_chunks.shape\n",
    "            bsz = bsz_k // self.num_chunks\n",
    "            quantized_embs = quantized_embs_chunks.view(bsz, dim_chunk * self.num_chunks)\n",
    "\n",
    "            query_offset = 0\n",
    "            pos_offset = query_dense.shape[0]\n",
    "            neg_offset = query_dense.shape[0] + pos_dense.shape[0]\n",
    "\n",
    "            query_quantized_embs = quantized_embs[:pos_offset]\n",
    "            pos_quantized_embs = quantized_embs[pos_offset:neg_offset]\n",
    "            neg_quantized_embs = quantized_embs[neg_offset:]\n",
    "\n",
    "        else:\n",
    "          query_quantized_embs = query_dense\n",
    "          pos_quantized_embs = pos_dense\n",
    "          neg_quantized_embs = neg_dense\n",
    "\n",
    "        query_sparse = self.sparse_layer(query_quantized_embs)\n",
    "        pos_sparse = self.sparse_layer(pos_quantized_embs)\n",
    "        neg_sparse = self.sparse_layer(neg_quantized_embs)\n",
    "\n",
    "        return query_dense,query_sparse,pos_dense,pos_sparse,neg_dense,neg_sparse,codebook_loss\n",
    "\n",
    "    def get_sparse_rep(self,inputs):\n",
    "        embs = self.model(**inputs)\n",
    "        dense_embs = get_contriever_emb(embs,inputs['attention_mask'])\n",
    "\n",
    "        if self.config['use_quantization']:\n",
    "            embeds = split_embedding_into_chunks(dense_embs,self.num_chunks)\n",
    "\n",
    "            quantized_embs_chunks, diff, _ = self.quantizer(embeds,False)\n",
    "\n",
    "            bsz_k, dim_chunk = quantized_embs_chunks.shape\n",
    "            bsz = bsz_k // self.num_chunks\n",
    "            quantized_embs = quantized_embs_chunks.view(bsz, dim_chunk * self.num_chunks)\n",
    "        else:\n",
    "            quantized_embs = dense_embs\n",
    "\n",
    "        sparse_rep = self.sparse_layer(quantized_embs)\n",
    "\n",
    "        return sparse_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zhA9IphYPqN"
   },
   "outputs": [],
   "source": [
    "# Model design choices\n",
    "\n",
    "num_chunks = 16\n",
    "vocab_size = 8192\n",
    "cluster_size = 6000\n",
    "dense_embed_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv3AeCHpwqjk"
   },
   "outputs": [],
   "source": [
    "# Config setting\n",
    "\n",
    "model_config = {\n",
    "    'use_quantization': True,\n",
    "    'freeze_contriver': False,\n",
    "    'freeze_vq': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "ApZGLUwpaLBr",
    "outputId": "8e8df8fb-d5e9-4211-db9b-c11ca6ad807a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msensai99\u001b[0m (\u001b[33mteam-layout\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250516_043359-d9gtbvlq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team-layout/LSR-VQ/runs/d9gtbvlq' target=\"_blank\">brisk-moon-15</a></strong> to <a href='https://wandb.ai/team-layout/LSR-VQ' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team-layout/LSR-VQ' target=\"_blank\">https://wandb.ai/team-layout/LSR-VQ</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team-layout/LSR-VQ/runs/d9gtbvlq' target=\"_blank\">https://wandb.ai/team-layout/LSR-VQ/runs/d9gtbvlq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/team-layout/LSR-VQ/runs/d9gtbvlq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7829958b3650>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights and biases reporting to monitor training and results\n",
    "\n",
    "wandb.init(project = \"LSR-VQ\", config = model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQdebk-1ZQ9k"
   },
   "outputs": [],
   "source": [
    "model = LSR_VQ(model_name,dense_embed_size//num_chunks,cluster_size,num_chunks,dense_embed_size,vocab_size,model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-OROxc9fQWr",
    "outputId": "0bad81df-6a6c-46ac-bc68-15b3e476a783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load trained weights\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "state_dict = load_file(\"/content/drive/MyDrive/685/checkpoints/NoVQ/checkpoint-35000/model.safetensors\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVGQZfiXZQ9k"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO9ltyZLZ3yI"
   },
   "outputs": [],
   "source": [
    "# Custom trainer\n",
    "class LSRVQ_Trainer(Trainer):\n",
    "\n",
    "    def __init__(self, *args, trainer_config,**kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = trainer_config\n",
    "        self.query_reg_lambda = self.config['query_lambda']\n",
    "        self.passage_reg_lambda = self.config['passage_lambda']\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False,num_items_in_batch=None):\n",
    "\n",
    "        query_dense, query_sparse, pos_dense, pos_sparse, neg_dense, neg_sparse, codebook_loss = self.model(inputs)\n",
    "\n",
    "        c_loss = contrastive_loss(query_sparse,pos_sparse,neg_sparse)\n",
    "\n",
    "        loss = c_loss\n",
    "        logs = {\"contrastive_loss\": c_loss.item()}\n",
    "\n",
    "        # Query sparsity loss\n",
    "        if self.config['query_sparsity_loss']:\n",
    "          query_reg_loss = torch.sum(torch.mean(torch.abs(query_sparse), dim=0) ** 2)\n",
    "          q_loss = self.query_reg_lambda*query_reg_loss\n",
    "          loss += q_loss\n",
    "          logs[\"query_sparsity_loss\"] = q_loss.item()\n",
    "\n",
    "        # Document sparsity loss\n",
    "        passage_sparse = torch.cat([pos_sparse,neg_sparse], dim=0)\n",
    "        passage_reg_loss = torch.sum(torch.mean(torch.abs(passage_sparse), dim=0) ** 2)\n",
    "        p_loss = self.passage_reg_lambda*passage_reg_loss\n",
    "        logs[\"passage_sparsity_loss\"] = p_loss.item()\n",
    "\n",
    "        loss += p_loss\n",
    "\n",
    "        # VQ codebook loss\n",
    "        if self.config['codebook_loss']:\n",
    "          loss += codebook_loss\n",
    "          logs[\"codebook_loss\"] = codebook_loss.item()\n",
    "\n",
    "        logs[\"total_loss\"] = loss.item()\n",
    "\n",
    "        if self.config['verbose']:\n",
    "          if self.config['verbose']:\n",
    "              for k, v in logs.items():\n",
    "                  print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "        # Log to wandb\n",
    "        if wandb.run is not None:\n",
    "            wandb.log(logs)\n",
    "\n",
    "        return (loss,torch.zeros(1)) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fveksc6Zwr8"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./weights\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_total_limit=50,\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    fp16=True,\n",
    "    report_to='none',\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hfivo-GLyxzh"
   },
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    'query_lambda': 0.5,\n",
    "    'passage_lambda': 0.5,\n",
    "    'query_sparsity_loss': True,\n",
    "    'codebook_loss': True,\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3MtVX_Dq2Wy"
   },
   "outputs": [],
   "source": [
    "trainer = LSRVQ_Trainer(\n",
    "        trainer_config=trainer_config,\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        data_collator = custom_data_collator,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = eval_dataset,\n",
    "        )\n",
    "\n",
    "trainer.can_return_loss=True\n",
    "\n",
    "def custom_eval_dataloader(eval_set):\n",
    "    return DataLoader(\n",
    "    eval_set,\n",
    "    batch_size=training_args.eval_batch_size,\n",
    "    sampler=RandomSampler(eval_dataset),\n",
    "    collate_fn=trainer.data_collator,\n",
    ")\n",
    "\n",
    "trainer.get_eval_dataloader = custom_eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SKTck8JRZQ9l",
    "outputId": "761d0797-2de1-4799-8a2c-be14a4b9e52a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35360' max='35360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35360/35360 3:21:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.265300</td>\n",
       "      <td>1.427986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>1.232941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>1.303543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.741200</td>\n",
       "      <td>0.856673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>1.020975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.781890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.665500</td>\n",
       "      <td>0.697751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.575200</td>\n",
       "      <td>0.716633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.573100</td>\n",
       "      <td>0.659197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.543900</td>\n",
       "      <td>0.666202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.696619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.670730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.845610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.674649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.582616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.578235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.621329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.577912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.386400</td>\n",
       "      <td>0.472182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.475129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.444091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.459682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.448718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.423857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.416342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.387520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>0.382583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.251500</td>\n",
       "      <td>0.355504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.336753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.332849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.200900</td>\n",
       "      <td>0.330499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.316555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.301584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.292331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.290204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35360, training_loss=0.4392120920155383, metrics={'train_runtime': 12094.8808, 'train_samples_per_second': 187.104, 'train_steps_per_second': 2.924, 'total_flos': 0.0, 'train_loss': 0.4392120920155383, 'epoch': 5.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Sndzj0Z-Qc"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "up5wVcoOZQ9l"
   },
   "outputs": [],
   "source": [
    "# Load dev qrels and metadata\n",
    "\n",
    "queries_dev = tsv_to_dict_unqiue(os.path.join('/content/drive/MyDrive/685/data', \"queries.dev.small.tsv\"))\n",
    "qrels_dev = tsv_to_dict_multiple(os.path.join('/content/drive/MyDrive/685/data', \"qrels.dev.small.tsv\"), keys = [0, 2])\n",
    "\n",
    "with open('/content/drive/MyDrive/685/embeddings/dev/passage_ids.json') as f:\n",
    "    inference_passage_ids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7QRTTCPfPlS"
   },
   "outputs": [],
   "source": [
    "# Compute sparse embeddings \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "def encode_texts(model, tokenizer, text_ds, batch_size, verbose=False):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    text_ids = [i['_id'] for i in text_ds]\n",
    "    dataloader = DataLoader(text_ds, batch_size=batch_size, shuffle=False)\n",
    "    allemb = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            prepare_batch = [batch['text'][i] for i in range(len(batch['text']))]\n",
    "            tokenized_texts = tokenizer.batch_encode_plus(\n",
    "                prepare_batch,\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                add_special_tokens=True,\n",
    "            ).to(device)\n",
    "            if verbose:\n",
    "                print(\"Batch size:\", len(batch['text']))\n",
    "                print(f\"Tokenized texts shape: {tokenized_texts['input_ids'].shape}\")\n",
    "                print(f\"Decode text sample {tokenizer.decode(tokenized_texts['input_ids'][0])}\")\n",
    "            emb = model.get_sparse_rep(tokenized_texts)\n",
    "            allemb.append(emb)\n",
    "    allemb = torch.cat(allemb, dim=0)\n",
    "    return allemb, text_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ae_M0bgZQ9l"
   },
   "outputs": [],
   "source": [
    "# Corpurs and dev queries dataset\n",
    "\n",
    "corpus_ds = Dataset.from_dict({'_id':inference_passage_ids,'text':[passages[_id] for _id in inference_passage_ids]})\n",
    "queries_ds = Dataset.from_dict({'_id':list(queries_dev.keys()),'text':list(queries_dev.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H-KuPc-ZQ9l"
   },
   "source": [
    "### Top-k Sparsification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_topk = 1024\n",
    "query_topk = 16\n",
    "min_weight = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taE_1AViZQ9l",
    "outputId": "efd966a2-407c-49db-edf1-f30045c86369"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:29<00:00, 11.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# Passage sparsification\n",
    "\n",
    "p_sparse_embeddings, passage_ids = encode_texts(model, tokenizer, corpus_ds, batch_size=1024)\n",
    "\n",
    "# Apply top-k sparsification\n",
    "values, indices = torch.topk(p_sparse_embeddings.abs(), k=passage_topk, dim=1)\n",
    "sparse_embeddings = torch.zeros_like(p_sparse_embeddings)\n",
    "sparse_embeddings.scatter_(1, indices, p_sparse_embeddings.gather(1, indices))\n",
    "\n",
    "passage_sparse_embeddings = sparse_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MijyO5f3ZQ9m",
    "outputId": "92b6c4c3-2416-4034-9ba7-a0881c05040b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:08<00:00,  6.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Query Sparsification\n",
    "\n",
    "q_sparse_embeddings, query_ids = encode_texts(model, tokenizer, queries_ds, batch_size=128)\n",
    "\n",
    "values, indices = torch.topk(q_sparse_embeddings.abs(), k=query_topk, dim=1)\n",
    "sparse_embeddings = torch.zeros_like(q_sparse_embeddings)\n",
    "sparse_embeddings.scatter_(1, indices, q_sparse_embeddings.gather(1, indices))\n",
    "sparse_embeddings[sparse_embeddings.abs() < min_weight] = 0\n",
    "query_sparse_embeddings = sparse_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meX0DM3wZQ9l"
   },
   "source": [
    "### Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vN1WNIyVDzU"
   },
   "outputs": [],
   "source": [
    "rows, cols, data = [], [], []\n",
    "\n",
    "for j, doc_id in enumerate(passage_ids):\n",
    "    doc_embedding = passage_sparse_embeddings[j]\n",
    "    # Get non-zero indices and their values\n",
    "    nonzero_indices = np.nonzero(doc_embedding)[0]\n",
    "    for idx in nonzero_indices:\n",
    "        weight = doc_embedding[idx]\n",
    "        if weight > min_weight:\n",
    "          rows.append(j)\n",
    "          cols.append(idx)\n",
    "          data.append(float(weight))\n",
    "\n",
    "optimized_index = csr_matrix((data, (rows, cols)), shape = (len(passage_ids), vocab_size), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHD9ghP6ZQ9m"
   },
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6OtqjMtZ4-S",
    "outputId": "28d12d2e-d78a-4eaa-e99c-c9f9da6f16d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating queries (csr)...: 100%|██████████| 14/14 [00:04<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "all_results = {}\n",
    "for start in tqdm(range(0, len(queries_ds), batch_size), desc = \"Evaluating queries (csr)...\"):\n",
    "    end = min(start + batch_size, len(queries_ds))\n",
    "    query_chunk = query_sparse_embeddings[start:end]\n",
    "    scores_chunk = query_chunk @ optimized_index.T  # shape: [batch_size, num_passages]\n",
    "\n",
    "    topk_idx = np.argpartition(-scores_chunk, 1000, axis = 1)[:, :1000]\n",
    "    for i in range(scores_chunk.shape[0]):\n",
    "        passage_scores = scores_chunk[i]\n",
    "        top_i = topk_idx[i]\n",
    "        top_indices = top_i[np.argsort(-passage_scores[top_i])]\n",
    "        all_results[query_ids[start + i]] = [(passage_ids[t], passage_scores[t]) for t in top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sHOkG_QZQ9m"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxgeA_x8UBnQ"
   },
   "outputs": [],
   "source": [
    "run_dict = {}\n",
    "for qid, results in all_results.items():\n",
    "    run_dict[qid] = {\n",
    "        str(passage_id): float(score)\n",
    "        for passage_id, score in results\n",
    "    }\n",
    "run = Run(run_dict)\n",
    "\n",
    "qrels_dict = {\n",
    "    qid: {str(passage_id): 1 for passage_id in qrels_dev[qid]}\n",
    "    for qid in all_results.keys()\n",
    "}\n",
    "qrels = Qrels(qrels_dict)\n",
    "\n",
    "# Evaluate using rankx\n",
    "metrics = [\"ndcg@10\", \"ndcg@100\", \"ndcg@1000\", \"recall@10\", \"recall@100\", \"recall@1000\", \"mrr@10\"]\n",
    "results = evaluate(qrels, run, metrics)\n",
    "\n",
    "m = (results[\"mrr@10\"],\n",
    "    {\n",
    "        '10': results[\"ndcg@10\"],\n",
    "        '100': results[\"ndcg@100\"],\n",
    "        '1000': results[\"ndcg@1000\"]\n",
    "    },\n",
    "    {\n",
    "        '10': results[\"recall@10\"],\n",
    "        '100': results[\"recall@100\"],\n",
    "        '1000': results[\"recall@1000\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw4TZmxc2VSu",
    "outputId": "e62109f0-cab9-4e7b-8e5e-0fb5a214b0cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3973082958111612),\n",
       " {'10': np.float64(0.42941978161620187),\n",
       "  '100': np.float64(0.47334865342734245),\n",
       "  '1000': np.float64(0.49263936881957143)},\n",
       " {'10': np.float64(0.5501552053486151),\n",
       "  '100': np.float64(0.7603271251193887),\n",
       "  '1000': np.float64(0.9148519579751672)})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDuIAepd2XMI",
    "outputId": "57d66056-e72b-40f0-a4cf-d673720759e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.29163420430254244),\n",
       " {'10': np.float64(0.3340381478056171),\n",
       "  '100': np.float64(0.39728924184075215),\n",
       "  '1000': np.float64(0.41999863894721956)},\n",
       " {'10': np.float64(0.48475405921681),\n",
       "  '100': np.float64(0.7870582617000954),\n",
       "  '1000': np.float64(0.9635148042024833)})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqA5Cg7lk0OW",
    "outputId": "f7efaf4e-df8f-4aad-96c4-fcd16dc01721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.225375676536135),\n",
       " {'10': np.float64(0.26898959359941194),\n",
       "  '100': np.float64(0.34772644249372625),\n",
       "  '1000': np.float64(0.37047270527950577)},\n",
       " {'10': np.float64(0.4211437440305635),\n",
       "  '100': np.float64(0.7980659025787966),\n",
       "  '1000': np.float64(0.9747731614135625)})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcXZOj-qoquj",
    "outputId": "09aa0a03-d582-4d96-c49b-ba437c05cad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.21746043116386957),\n",
       " {'10': np.float64(0.2660949538941461),\n",
       "  '100': np.float64(0.3493895628275042),\n",
       "  '1000': np.float64(0.3683083365871593)},\n",
       " {'10': np.float64(0.4358046800382044),\n",
       "  '100': np.float64(0.8304560649474689),\n",
       "  '1000': np.float64(0.9763849092645653)})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 epochs\n",
    "# all losses, high lambdas\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfGw__fWat75",
    "outputId": "d9ad8412-96dc-4e89-bcab-1977dcfa34f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6774686746713968),\n",
       " {'10': np.float64(0.7210872497108043),\n",
       "  '100': np.float64(0.7418761424412927),\n",
       "  '1000': np.float64(0.7458216151356812)},\n",
       " {'10': np.float64(0.8706542502387774),\n",
       "  '100': np.float64(0.9649116523400192),\n",
       "  '1000': np.float64(0.9950453677172876)})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 epochs 5L\n",
    "# all losses, high lambda\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3jjPxuZoI3q",
    "outputId": "4f23051d-2413-47ea-f02d-fef9af7c8266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7131263360167371),\n",
       " {'10': np.float64(0.7521769361768146),\n",
       "  '100': np.float64(0.7711645309332931),\n",
       "  '1000': np.float64(0.774010873260608)},\n",
       " {'10': np.float64(0.88810888252149),\n",
       "  '100': np.float64(0.9743791786055397),\n",
       "  '1000': np.float64(0.9963705826170008)})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 epochs\n",
    "# all lossses, high lambda\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2JGqAEbcj2U",
    "outputId": "7b3d1f54-0c55-4d70-d569-27dc51baa615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2301698162550598),\n",
       " {'10': np.float64(0.27255224748544954),\n",
       "  '100': np.float64(0.3363970047951509),\n",
       "  '1000': np.float64(0.3606111138861944)},\n",
       " {'10': np.float64(0.41793218720152814),\n",
       "  '100': np.float64(0.7232449856733524),\n",
       "  '1000': np.float64(0.9129297994269341)})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5L evaluation - VQ\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkXF__k9myt_",
    "outputId": "74312a6b-d804-4436-af30-be8ef46fa0c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.46837011643243737),\n",
       " {'10': np.float64(0.5200407078961042),\n",
       "  '100': np.float64(0.5662247216678938),\n",
       "  '1000': np.float64(0.5754124549094598)},\n",
       " {'10': np.float64(0.6971227316141355),\n",
       "  '100': np.float64(0.9091690544412607),\n",
       "  '1000': np.float64(0.9800740210124164)})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5L evaluation - without VQ\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWD6Ed6G009V",
    "outputId": "157a8b0d-9dfc-4fa8-a7a1-376b98d5ea74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.720491767862828),\n",
       " {'10': np.float64(0.7599282328907433),\n",
       "  '100': np.float64(0.7776452977217517),\n",
       "  '1000': np.float64(0.7803430710930395)},\n",
       " {'10': np.float64(0.8947946513849093),\n",
       "  '100': np.float64(0.9746895893027699),\n",
       "  '1000': np.float64(0.9954990448901623)})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VQ with KMeans intitialization\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sR7qz5m9Q2d",
    "outputId": "e4aee369-ddbd-4a28-e7ae-f9395ce16013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2298591781507254),\n",
       " {'10': np.float64(0.2724794560437748),\n",
       "  '100': np.float64(0.3377962385283097),\n",
       "  '1000': np.float64(0.3615194341372948)},\n",
       " {'10': np.float64(0.4181470869149952),\n",
       "  '100': np.float64(0.7311962750716332),\n",
       "  '1000': np.float64(0.9163681948424068)})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5L evaluation - VQ with KMeans intialization\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULJPEOaKShSw",
    "outputId": "405c12ee-3130-4848-963a-5cd2ef12e9b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg sparsity 16.0\n"
     ]
    }
   ],
   "source": [
    "#check query sparsity\n",
    "avg_sparsity = 0\n",
    "for i in range(len(query_sparse_embeddings)):\n",
    "  avg_sparsity += np.where(query_sparse_embeddings[i] > 0)[0].shape[0]\n",
    "  # print(np.where(query_sparse_embeddings[i] > 0)[0].shape)\n",
    "print('avg sparsity', avg_sparsity/len(query_sparse_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUoW_5DPSyUJ",
    "outputId": "53069cf5-8a81-4fd1-9f98-3f50b26a670f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average sparsity 64.0\n"
     ]
    }
   ],
   "source": [
    "# check passage sparsity\n",
    "avg_sparsity = 0\n",
    "for row_idx in range(optimized_index.shape[0]):\n",
    "    row_data = optimized_index.getrow(row_idx)\n",
    "    non_zero_count = row_data.nnz\n",
    "    avg_sparsity += non_zero_count\n",
    "    # print(non_zero_count)\n",
    "print('average sparsity',avg_sparsity/optimized_index.shape[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dMfgNUYhUb1y"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorchbase]",
   "language": "python",
   "name": "conda-env-pytorchbase-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15aba9589be14607bf6dca7a63a7c8de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e677f8faf420453093f2d80eebdf2cf9",
      "placeholder": "​",
      "style": "IPY_MODEL_77749fcb19554cc5a8ee64c0eb2b84cb",
      "value": " 502890/0 [01:08&lt;00:00, 8382.25 examples/s]"
     }
    },
    "180ffce0843e4ddaaded2222aeda662b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b1c5d554a9e450d9e3cf698391e6fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbc08f621c004472a2f9af3295086e2c",
       "IPY_MODEL_34126021bd6d421cb3f3eec0afa1e958",
       "IPY_MODEL_c39b8c749a0341589d072716ade1a22e"
      ],
      "layout": "IPY_MODEL_b7c7d0ce558a47df91fed147bd380dfc"
     }
    },
    "1ef9ea49b2424d15b85aae69b06c5852": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3984cb7e6ec549dd82ccd8eb6620837a",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffddd421c3444105b97180ce4444d5c4",
      "value": 112
     }
    },
    "23cf924964f14ddbb5a37b43e3bf1701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24faabb55d10494d900d8a3625fde0c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5982017a8d95409691150c47d52db356",
      "max": 321,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64f6df30716d4812a8b5900879a2cf75",
      "value": 321
     }
    },
    "293ab459c5bd413e8f35ec10b3d421ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee6c3f37424442c2b0eaa01bf6efb5b2",
       "IPY_MODEL_24faabb55d10494d900d8a3625fde0c2",
       "IPY_MODEL_f39a47d9662a4d4abe07a280f094b5a7"
      ],
      "layout": "IPY_MODEL_bde590aaf4604c6987e35c264210fea4"
     }
    },
    "2d680f4fb5ac499a9600c33af63b7b97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f63de6447e84f7f9bfeac7c98f906a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3216f36606be452289155fa4b2f4791a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34126021bd6d421cb3f3eec0afa1e958": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f25f72d28494d37b4ec7664bb64d224",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40f187e6915343d484f18a7dc52c712a",
      "value": 231508
     }
    },
    "3984cb7e6ec549dd82ccd8eb6620837a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40f187e6915343d484f18a7dc52c712a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4dc92e8965184b2698482c27af83685f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "515d5e1f571945d2af33794169e7e7e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54079b2a69d64e848230111e308cb14a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "562223988d1a4de2a97d87fe69351495": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5982017a8d95409691150c47d52db356": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a49b3c7ec05444ba5bedee37ada3cf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64e9e702d48346ddba2fbf9278eed370": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e27a2140295f43f5abccb9c516233dff",
      "placeholder": "​",
      "style": "IPY_MODEL_760ef407acf24e7a9faa37d0ca8a9035",
      "value": " 112/112 [00:00&lt;00:00, 16.1kB/s]"
     }
    },
    "64f6df30716d4812a8b5900879a2cf75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "652f7b05eb6d47df88db900dcb8c8df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3216f36606be452289155fa4b2f4791a",
      "placeholder": "​",
      "style": "IPY_MODEL_23cf924964f14ddbb5a37b43e3bf1701",
      "value": "Generating train split: "
     }
    },
    "6e67397d1a8c4e1e8240663eb43dd5b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7196cf136d6b4ef7a18485fe37759cd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "760ef407acf24e7a9faa37d0ca8a9035": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77749fcb19554cc5a8ee64c0eb2b84cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c41a9bce7724dc895a584c0fc6bf601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ebbb6a9010e4fef92610c005380708d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b4e3fedcff54072ba5443c0d14f65f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e67397d1a8c4e1e8240663eb43dd5b0",
      "placeholder": "​",
      "style": "IPY_MODEL_5a49b3c7ec05444ba5bedee37ada3cf3",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "9f25f72d28494d37b4ec7664bb64d224": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae2b113c8b5647028946e5180745d22a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b4e3fedcff54072ba5443c0d14f65f5",
       "IPY_MODEL_1ef9ea49b2424d15b85aae69b06c5852",
       "IPY_MODEL_64e9e702d48346ddba2fbf9278eed370"
      ],
      "layout": "IPY_MODEL_f7de1fe488f64558b498c4f103779bea"
     }
    },
    "b3b160f7647a4a718b943a29ecc37989": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7c7d0ce558a47df91fed147bd380dfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc720f41c4e948dfac60f055cb89afa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eebf15813a71406c82f70a2f355e9a7d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7000fadbb584f36ae6c094a7aa69475",
      "value": 1
     }
    },
    "bc93cf9322b54e5c84330e6e9cf6d83b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_180ffce0843e4ddaaded2222aeda662b",
      "placeholder": "​",
      "style": "IPY_MODEL_d8fc27082e904831804a20ca910f6aa8",
      "value": "tokenizer.json: 100%"
     }
    },
    "bdb15b1024f84ab9b5223bb775229ebb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bde590aaf4604c6987e35c264210fea4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c39b8c749a0341589d072716ade1a22e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ebbb6a9010e4fef92610c005380708d",
      "placeholder": "​",
      "style": "IPY_MODEL_e528a474e04645fd8192053141cdf6a5",
      "value": " 232k/232k [00:00&lt;00:00, 4.40MB/s]"
     }
    },
    "cbc08f621c004472a2f9af3295086e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3c4653d90b7415191185dbbe371ccbd",
      "placeholder": "​",
      "style": "IPY_MODEL_2f63de6447e84f7f9bfeac7c98f906a1",
      "value": "vocab.txt: 100%"
     }
    },
    "cd9f4fa39a9c4602bbd81148f1235180": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_652f7b05eb6d47df88db900dcb8c8df9",
       "IPY_MODEL_bc720f41c4e948dfac60f055cb89afa0",
       "IPY_MODEL_15aba9589be14607bf6dca7a63a7c8de"
      ],
      "layout": "IPY_MODEL_4dc92e8965184b2698482c27af83685f"
     }
    },
    "cffb4d78e32443078154d0a4c3015ec0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3c4653d90b7415191185dbbe371ccbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8fc27082e904831804a20ca910f6aa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e27a2140295f43f5abccb9c516233dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e528a474e04645fd8192053141cdf6a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e677f8faf420453093f2d80eebdf2cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7000fadbb584f36ae6c094a7aa69475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb178f4578dc40aaa844788bbc1c79ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdb15b1024f84ab9b5223bb775229ebb",
      "placeholder": "​",
      "style": "IPY_MODEL_54079b2a69d64e848230111e308cb14a",
      "value": " 466k/466k [00:00&lt;00:00, 7.87MB/s]"
     }
    },
    "ee6c3f37424442c2b0eaa01bf6efb5b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d680f4fb5ac499a9600c33af63b7b97",
      "placeholder": "​",
      "style": "IPY_MODEL_b3b160f7647a4a718b943a29ecc37989",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "eebf15813a71406c82f70a2f355e9a7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ef51f360e81347c9b64eef18136351ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cffb4d78e32443078154d0a4c3015ec0",
      "max": 466081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7196cf136d6b4ef7a18485fe37759cd8",
      "value": 466081
     }
    },
    "f39a47d9662a4d4abe07a280f094b5a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_515d5e1f571945d2af33794169e7e7e6",
      "placeholder": "​",
      "style": "IPY_MODEL_562223988d1a4de2a97d87fe69351495",
      "value": " 321/321 [00:00&lt;00:00, 37.6kB/s]"
     }
    },
    "f72ca9bb3d7140cfbd0fe3991e639b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc93cf9322b54e5c84330e6e9cf6d83b",
       "IPY_MODEL_ef51f360e81347c9b64eef18136351ff",
       "IPY_MODEL_eb178f4578dc40aaa844788bbc1c79ff"
      ],
      "layout": "IPY_MODEL_7c41a9bce7724dc895a584c0fc6bf601"
     }
    },
    "f7de1fe488f64558b498c4f103779bea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffddd421c3444105b97180ce4444d5c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
