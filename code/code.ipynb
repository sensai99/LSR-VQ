{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive setup"
      ],
      "metadata": {
        "id": "NqOAju4oEoCv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01BYZtqZklaa",
        "outputId": "9a653089-4400-49d4-9085-1005a5453191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-43ssCagua2f",
        "outputId": "04ce5657-d8bc-43cb-caf2-c7d5b1c0f8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/685/code\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/685/code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required libraries"
      ],
      "metadata": {
        "id": "VasyZiEuElRC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V6ZSHNNr0c5c",
        "outputId": "3cdd660f-31d7-41b9-ab83-2973c1061f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting ir_datasets\n",
            "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting rank-eval\n",
            "  Downloading rank_eval-0.1.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting ranx\n",
            "  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir_datasets) (4.13.4)\n",
            "Collecting inscriptis>=2.2.0 (from ir_datasets)\n",
            "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir_datasets) (5.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir_datasets) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from ir_datasets) (2.32.3)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir_datasets)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
            "Collecting lz4>=3.1.10 (from ir_datasets)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting warc3-wet>=0.2.3 (from ir_datasets)\n",
            "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir_datasets)\n",
            "  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting ijson>=3.1.3 (from ir_datasets)\n",
            "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting unlzw3>=0.2.1 (from ir_datasets)\n",
            "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.11/dist-packages (from ir_datasets) (18.1.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.11/dist-packages (from rank-eval) (0.60.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rank-eval) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from rank-eval) (0.9.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from ranx) (13.9.4)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from ranx) (3.10.16)\n",
            "Collecting cbor2 (from ranx)\n",
            "  Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from ranx) (0.13.2)\n",
            "Collecting fastparquet (from ranx)\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.6)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54.1->rank-eval) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir_datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir_datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir_datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir_datasets) (2025.1.31)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx) (2.10.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->rank-eval) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rank-eval) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->ranx) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->ranx) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->ranx) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_eval-0.1.3-py3-none-any.whl (17 kB)\n",
            "Downloading ranx-0.3.20-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
            "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
            "Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: warc3-wet-clueweb09, cbor\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=714904267a6f6226926f03a8b8977e1f47fef89a9be6c92efe97270c984f8a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53930 sha256=661892f77d2e444390a5b3a21d544b3b6262433ab4e23181733cd2918e4fbefc\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n",
            "Successfully built warc3-wet-clueweb09 cbor\n",
            "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, trec-car-tools, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lz4, cbor2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, inscriptis, rank-eval, nvidia-cusolver-cu12, ir_datasets, fastparquet, ranx\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed cbor-1.0.0 cbor2-5.6.5 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir_datasets-0.5.10 lz4-4.4.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rank-eval-0.1.3 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install torch ir_datasets wandb numpy scikit-learn sentence-transformers transformers tqdm scipy matplotlib rank-eval ranx\n",
        "!pip install faiss-cpu\n",
        "# !pip uninstall faiss-gpu-cu11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "hBgRMwrOGoaK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "geJWQmK70Xcv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from utils import split_embedding_into_chunks\n",
        "from dataset import DataProcessor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Processor"
      ],
      "metadata": {
        "id": "PX2E9QB1cs55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingProcessor:\n",
        "\n",
        "    def __init__(self, data_processor, model, tokenizer, emb_root_dir, batch_size = 128, device = 'cpu') -> None:\n",
        "        self.data_processor = data_processor\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.emb_dim = None\n",
        "        self.emb_root_dir = emb_root_dir\n",
        "        self.device = device\n",
        "\n",
        "        self.embeddings_path = {\n",
        "            'train': {\n",
        "                'passage_embs': os.path.join(self.emb_root_dir, 'train', 'passage_embeddings.pt'),\n",
        "                'query_embs': os.path.join(self.emb_root_dir, 'dev', 'query_embeddings.pt'),\n",
        "                'passage_ids': os.path.join(self.emb_root_dir, 'train', 'passage_ids.json'),\n",
        "                'query_ids': os.path.join(self.emb_root_dir, 'dev', 'query_ids.json')\n",
        "            },\n",
        "            'dev': {\n",
        "                'passage_embs': os.path.join(self.emb_root_dir, 'dev', 'passage_embeddings.pt'),\n",
        "                'query_embs': os.path.join(self.emb_root_dir, 'dev', 'query_embeddings.pt'),\n",
        "                'passage_ids': os.path.join(self.emb_root_dir, 'dev', 'passage_ids.json'),\n",
        "                'query_ids': os.path.join(self.emb_root_dir, 'dev', 'query_ids.json')\n",
        "            }\n",
        "        }\n",
        "        self.passages, self.queries_train, self.queries_dev, self.qrels_train, self.qrels_dev = None, None, None, None, None\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        return\n",
        "\n",
        "    # Used to combine the embeddings of all the tokens\n",
        "    # Contriever model\n",
        "    def mean_pooling(self, token_embeddings, mask):\n",
        "        token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
        "        sentence_embeddings = token_embeddings.sum(dim = 1) / mask.sum(dim = 1)[..., None]\n",
        "        return sentence_embeddings\n",
        "\n",
        "    def filter_data(self, passages, queries, qrels):\n",
        "        relevant_passage_ids = set()\n",
        "        for qid in qrels:\n",
        "            relevant_passage_ids.update(qrels[qid])\n",
        "        passages = {passage_id: passages[passage_id] for passage_id in relevant_passage_ids}\n",
        "        passage_ids = list(passages.keys())\n",
        "\n",
        "        qrels = {qid: qrels[qid] for qid in queries if qid in qrels}\n",
        "\n",
        "        qrels_ = {}\n",
        "        queries_ = {}\n",
        "        for qid in queries:\n",
        "            if qid in qrels:\n",
        "                qrels_[qid] = qrels[qid]\n",
        "                queries_[qid] = queries[qid]\n",
        "\n",
        "        query_ids = list(qrels_.keys())\n",
        "\n",
        "        return {'passages': passages, 'queries': queries_, 'qrels': qrels_, 'passage_ids': passage_ids, 'query_ids': query_ids}\n",
        "\n",
        "    def get_filtered_data(self, mode = 'train'):\n",
        "        if mode not in ['train', 'dev']:\n",
        "            raise ValueError('Invalid mode!')\n",
        "\n",
        "        if self.passages == None:\n",
        "            # If they are not loaded yet, load them\n",
        "            raw_data = self.data_processor.get_data()\n",
        "            self.passages, self.queries_train, self.queries_dev, self.qrels_train, self.qrels_dev = raw_data['passages'], raw_data['queries_train'], raw_data['queries_dev'], raw_data['qrels_train'], raw_data['qrels_dev']\n",
        "\n",
        "        filtered_data = {\n",
        "            'passage': None,\n",
        "            'query': None\n",
        "        }\n",
        "        if mode == 'train':\n",
        "            data = self.filter_data(passages = self.passages, queries = self.queries_train, qrels = self.qrels_train)\n",
        "            filtered_data['passage'] = {\n",
        "                'passages': data['passages'],\n",
        "                'passage_ids': data['passage_ids']\n",
        "            }\n",
        "            filtered_data['query'] = {\n",
        "                'queries': data['queries'],\n",
        "                'qrels': data['qrels'],\n",
        "                'query_ids': data['query_ids']\n",
        "            }\n",
        "\n",
        "        elif mode == 'dev':\n",
        "            data = self.filter_data(passages = self.passages, queries = self.queries_dev, qrels = self.qrels_dev)\n",
        "\n",
        "            # In case of development set, passages would be the entire collection (instead of the filtered ids using qrels)\n",
        "            filtered_data['passage'] = {\n",
        "                'passages': self.passages,\n",
        "                'passage_ids': list(self.passages.keys())\n",
        "            }\n",
        "            filtered_data['query'] = {\n",
        "                'queries': data['queries'],\n",
        "                'qrels': data['qrels'],\n",
        "                'query_ids': data['query_ids']\n",
        "            }\n",
        "\n",
        "        return filtered_data\n",
        "\n",
        "    def compute_embeddings(self, type = 'passage', mode = 'train', start = None, limit = None):\n",
        "        if type == None:\n",
        "            print('Embedding type not provided, Not computing embeddings!')\n",
        "            return\n",
        "\n",
        "        if type not in ['passage', 'query']:\n",
        "            raise ValueError('Invalid embedding type!')\n",
        "\n",
        "        data = self.get_filtered_data(mode)[type]\n",
        "        if type == 'query':\n",
        "            data = data['queries']\n",
        "        elif type == 'passage':\n",
        "            data = data['passages']\n",
        "\n",
        "        if limit is not None:\n",
        "            data = dict(list(data.items())[start: start + limit])\n",
        "            print('Number of passages:', len(data))\n",
        "\n",
        "        data_embeddings = []\n",
        "\n",
        "        ids = list(data.keys())\n",
        "        for i in tqdm(range(0, len(ids), self.batch_size), desc = f\"Encoding {type}\"):\n",
        "            batch_data = [data[id] for id in ids[i:i + self.batch_size]]\n",
        "\n",
        "            # Pad till the model's configured max_len (512)\n",
        "            batch_inputs = self.tokenizer(batch_data, padding = True, truncation = True, return_tensors = 'pt')\n",
        "            batch_inputs = {k: v.to(self.device) for k, v in batch_inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(batch_inputs[\"input_ids\"], batch_inputs[\"attention_mask\"])\n",
        "                batch_embeddings = self.mean_pooling(outputs[0], batch_inputs['attention_mask'])\n",
        "                data_embeddings.append(batch_embeddings)\n",
        "\n",
        "        data_embeddings = torch.cat(data_embeddings, dim = 0)\n",
        "\n",
        "        return data_embeddings, list(ids)\n",
        "\n",
        "    def load_or_save_passage_embeddings(self, mode = 'train', start= None, limit = None):\n",
        "        pass_embs_path = self.embeddings_path[mode]['passage_embs']\n",
        "        pass_ids_path = self.embeddings_path[mode]['passage_ids']\n",
        "\n",
        "        if os.path.exists(pass_embs_path) and os.path.exists(pass_ids_path):\n",
        "            print(\"Loading cached passage embeddings & ids...\")\n",
        "            passage_embeddings = torch.load(pass_embs_path).to(device = self.device)\n",
        "            self.emb_dim = passage_embeddings.shape[-1]\n",
        "\n",
        "            with open(pass_ids_path, \"r\") as f:\n",
        "                passage_ids = json.load(f)\n",
        "\n",
        "            return {\n",
        "                'embeddings':\n",
        "                    {\n",
        "                        'passage_embeddings': passage_embeddings\n",
        "                    },\n",
        "                'mappings': {\n",
        "                        'passage_ids': passage_ids\n",
        "                    }\n",
        "                }\n",
        "\n",
        "        passage_embeddings, passage_ids = self.compute_embeddings(type = 'passage', mode = mode, start = start, limit = limit)\n",
        "        self.emb_dim = passage_embeddings.shape[-1]\n",
        "\n",
        "        # Save embeddings to the appropriate path\n",
        "        torch.save(passage_embeddings, pass_embs_path)\n",
        "\n",
        "        # Save ID mappings\n",
        "        with open(pass_ids_path, \"w\") as f:\n",
        "            json.dump(passage_ids, f)\n",
        "\n",
        "        print(\"Embeddings & Mappings saved.\")\n",
        "\n",
        "        return {\n",
        "            'embeddings':\n",
        "                {\n",
        "                    'passage_embeddings': passage_embeddings\n",
        "                },\n",
        "            'mappings': {\n",
        "                    'passage_ids': passage_ids\n",
        "                }\n",
        "            }\n",
        "\n",
        "\n",
        "    def load_or_save_query_embeddings(self, mode = 'train'):\n",
        "        query_embs_path = self.embeddings_path[mode]['query_embs']\n",
        "        query_ids_path = self.embeddings_path[mode]['query_ids']\n",
        "\n",
        "        if os.path.exists(query_embs_path) and os.path.exists(query_ids_path):\n",
        "            print(\"Loading cached query embeddings & ids...\")\n",
        "            query_embeddings = torch.load(query_embs_path).to(device = self.device)\n",
        "            self.emb_dim = query_embeddings.shape[-1]\n",
        "\n",
        "            with open(query_ids_path, \"r\") as f:\n",
        "                query_ids = json.load(f)\n",
        "\n",
        "            return {\n",
        "                'embeddings':\n",
        "                    {\n",
        "                        'query_embeddings': query_embeddings\n",
        "                    },\n",
        "                'mappings': {\n",
        "                        'query_ids': query_ids\n",
        "                    }\n",
        "                }\n",
        "\n",
        "        query_embeddings, query_ids = self.compute_embeddings(type = 'query', mode = mode)\n",
        "        self.emb_dim = query_embeddings.shape[-1]\n",
        "\n",
        "        # Save embeddings to the appropriate path\n",
        "        torch.save(query_embeddings, query_embs_path)\n",
        "\n",
        "        with open(query_ids_path, \"w\") as f:\n",
        "            json.dump(query_ids, f)\n",
        "\n",
        "        print(\"Embeddings & Mappings saved.\")\n",
        "\n",
        "        return {\n",
        "            'embeddings':\n",
        "                {\n",
        "                    'query_embeddings': query_embeddings\n",
        "                },\n",
        "            'mappings': {\n",
        "                    'query_ids': query_ids\n",
        "                }\n",
        "            }\n",
        "\n",
        "    def load_or_save_embeddings(self, mode = 'train'):\n",
        "        pass_embs_path = self.embeddings_path[mode]['passage_embs']\n",
        "        query_embs_path = self.embeddings_path[mode]['query_embs']\n",
        "        pass_ids_path = self.embeddings_path[mode]['passage_ids']\n",
        "        query_ids_path = self.embeddings_path[mode]['query_ids']\n",
        "        print(pass_embs_path)\n",
        "\n",
        "        if os.path.exists(pass_embs_path) and os.path.exists(query_embs_path) and os.path.exists(pass_ids_path) and os.path.exists(query_ids_path):\n",
        "            print(\"Loading cached embeddings & ids...\")\n",
        "            passage_embeddings = torch.load(pass_embs_path, map_location = 'cpu')\n",
        "            query_embeddings = torch.load(query_embs_path, map_location = 'cpu')\n",
        "            # passage_embeddings = torch.load(pass_embs_path).to(device = self.device)\n",
        "            # query_embeddings = torch.load(query_embs_path).to(device = self.device)\n",
        "            self.emb_dim = passage_embeddings.shape[-1]\n",
        "\n",
        "            with open(pass_ids_path, \"r\") as f:\n",
        "                passage_ids = json.load(f)\n",
        "\n",
        "            with open(query_ids_path, \"r\") as f:\n",
        "                query_ids = json.load(f)\n",
        "\n",
        "            return {\n",
        "                'embeddings':\n",
        "                    {\n",
        "                        'passage_embeddings': passage_embeddings,\n",
        "                        'query_embeddings': query_embeddings\n",
        "                    },\n",
        "                'mappings': {\n",
        "                        'passage_ids': passage_ids,\n",
        "                        'query_ids': query_ids\n",
        "                    }\n",
        "                }\n",
        "\n",
        "        passage_embeddings, passage_ids = self.compute_embeddings(type = 'passage', mode = mode)\n",
        "        query_embeddings, query_ids = self.compute_embeddings(type = 'query', mode = mode)\n",
        "        self.emb_dim = passage_embeddings.shape[-1]\n",
        "\n",
        "        # Save embeddings to the appropriate path\n",
        "        torch.save(passage_embeddings, pass_embs_path)\n",
        "        torch.save(query_embeddings, query_embs_path)\n",
        "\n",
        "        # Save ID mappings\n",
        "        with open(pass_ids_path, \"w\") as f:\n",
        "            json.dump(passage_ids, f)\n",
        "\n",
        "        with open(query_ids_path, \"w\") as f:\n",
        "            json.dump(query_ids, f)\n",
        "\n",
        "        print(\"Embeddings & Mappings saved.\")\n",
        "\n",
        "        return {\n",
        "            'embeddings':\n",
        "                {\n",
        "                    'passage_embeddings': passage_embeddings,\n",
        "                    'query_embeddings': query_embeddings\n",
        "                },\n",
        "            'mappings': {\n",
        "                    'passage_ids': passage_ids,\n",
        "                    'query_ids': query_ids\n",
        "                }\n",
        "            }\n",
        "\n",
        "    def get_emb_dim(self):\n",
        "        if self.emb_dim is None:\n",
        "            raise ValueError('Embedding dimension not found!')\n",
        "\n",
        "        return self.emb_dim"
      ],
      "metadata": {
        "id": "MjlVOJqKcrIf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Quantizer"
      ],
      "metadata": {
        "id": "cWsK2oHPb-oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Quantize(nn.Module):\n",
        "    def __init__(self, dim, num_clusters, decay = 0.99, eps = 1e-5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_clusters = num_clusters\n",
        "        self.decay = decay\n",
        "        self.eps = eps\n",
        "\n",
        "        embed = torch.randn(dim, num_clusters)\n",
        "        self.register_buffer(\"embed\", embed)\n",
        "        self.register_buffer(\"cluster_size\", torch.zeros(num_clusters))\n",
        "        self.register_buffer(\"embed_avg\", embed.clone())\n",
        "\n",
        "    def forward(self, input):\n",
        "        flatten = input.reshape(-1, self.dim)\n",
        "        dist = (\n",
        "            flatten.pow(2).sum(1, keepdim = True)\n",
        "            - 2 * flatten @ self.embed\n",
        "            + self.embed.pow(2).sum(0, keepdim = True)\n",
        "        )\n",
        "        _, embed_ind = (-dist).max(1)\n",
        "        embed_onehot = F.one_hot(embed_ind, self.num_clusters).type(flatten.dtype)\n",
        "        embed_ind = embed_ind.view(*input.shape[:-1])\n",
        "        quantize = self.embed_code(embed_ind)\n",
        "\n",
        "        if self.training:\n",
        "            embed_onehot_sum = embed_onehot.sum(0)\n",
        "            embed_sum = flatten.transpose(0, 1) @ embed_onehot\n",
        "\n",
        "            self.cluster_size.data.mul_(self.decay).add_(\n",
        "                embed_onehot_sum, alpha=1 - self.decay\n",
        "            )\n",
        "            self.embed_avg.data.mul_(self.decay).add_(embed_sum, alpha=1 - self.decay)\n",
        "            n = self.cluster_size.sum()\n",
        "            cluster_size = (\n",
        "                (self.cluster_size + self.eps) / (n + self.num_clusters * self.eps) * n\n",
        "            )\n",
        "            embed_normalized = self.embed_avg / cluster_size.unsqueeze(0)\n",
        "            self.embed.data.copy_(embed_normalized)\n",
        "\n",
        "        quantize = input + (quantize - input).detach()\n",
        "\n",
        "        return quantize, embed_ind\n",
        "\n",
        "    def embed_code(self, embed_id):\n",
        "        return F.embedding(embed_id, self.embed.transpose(0, 1))"
      ],
      "metadata": {
        "id": "OEgjlYducK8m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Quantizer Hanlder"
      ],
      "metadata": {
        "id": "pd4bvjy3cGTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VQHandler:\n",
        "    def __init__(self, embedding_processor, quantizer = None, emb_dim = None, num_clusters = None, num_chunks = 32, batch_size = 512, device = 'cpu'):\n",
        "\n",
        "        if quantizer is not None:\n",
        "            self.quantizer = quantizer\n",
        "        else:\n",
        "            self.quantizer = Quantize(dim = emb_dim, num_clusters = num_clusters)\n",
        "\n",
        "        self.embedding_processor = embedding_processor\n",
        "        train_embeddings = self.embedding_processor.load_or_save_embeddings(mode = 'train')['embeddings']\n",
        "        dev_embeddings = self.embedding_processor.load_or_save_embeddings(mode = 'dev')['embeddings']\n",
        "\n",
        "        self.train_query_embeddings = train_embeddings['query_embeddings']\n",
        "        self.train_passage_embeddings = dev_embeddings['passage_embeddings']\n",
        "        self.dev_query_embeddings = dev_embeddings['query_embeddings']\n",
        "        self.dev_passage_embeddings = dev_embeddings['passage_embeddings']\n",
        "\n",
        "        # Number of chunks each emb to be divided into\n",
        "        self.num_chunks = num_chunks\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def train(self):\n",
        "        self.quantizer.training = True\n",
        "        # train_query_chunked_embs = split_embedding_into_chunks(self.train_query_embeddings, self.num_chunks)\n",
        "        train_pass_chunked_embs = split_embedding_into_chunks(self.train_passage_embeddings, self.num_chunks)\n",
        "\n",
        "        # embeddings = torch.cat((train_query_chunked_embs, train_pass_chunked_embs), dim = 0)\n",
        "\n",
        "        for i in tqdm(range(0, train_pass_chunked_embs.shape[0], self.batch_size), desc = \"Training codebook vectors\"):\n",
        "            batch_embs = train_pass_chunked_embs[i:i + self.batch_size].to(device = self.device)\n",
        "            _, code = self.quantizer(batch_embs)\n",
        "\n",
        "        self.quantizer.training = False\n",
        "        return self.quantizer\n",
        "\n",
        "    def inference(self, type = 'passage', mode = 'dev'):\n",
        "\n",
        "        embeddings = None\n",
        "        if mode == 'dev':\n",
        "            if type == 'passage':\n",
        "                embeddings = self.dev_passage_embeddings\n",
        "            elif type == 'query':\n",
        "                embeddings = self.dev_query_embeddings\n",
        "\n",
        "        if mode == 'train':\n",
        "            if type == 'passage':\n",
        "                embeddings = self.train_passage_embeddings\n",
        "            elif type == 'query':\n",
        "                embeddings = self.train_query_embeddings\n",
        "\n",
        "        # Get the code book vectors for each passage in the devlopment set\n",
        "        self.quantizer.training = False\n",
        "        code_indices = []\n",
        "        for i in tqdm(range(0, embeddings.shape[0], self.batch_size), desc = \"Vector quantizing...\"):\n",
        "            batch_embs = embeddings[i:i + self.batch_size].to(device = self.device)\n",
        "            batch_chunked_embs = split_embedding_into_chunks(batch_embs, self.num_chunks)\n",
        "            _, code = self.quantizer(batch_chunked_embs)\n",
        "            code = code.view(-1, self.num_chunks)\n",
        "            code_indices.append(code)\n",
        "\n",
        "        code_indices = torch.cat(code_indices, dim = 0)\n",
        "\n",
        "        return code_indices"
      ],
      "metadata": {
        "id": "pTAQBOSbb9Io"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main.py"
      ],
      "metadata": {
        "id": "pA1XOw5ndDA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    - Load the raw dataset\n",
        "'''\n",
        "data_processor = DataProcessor(data_root_dir = '../data')\n",
        "data = data_processor.get_data()\n",
        "passages, queries_train, queries_dev, qrels_train, qrels_dev = data['passages'], data['queries_train'], data['queries_dev'], data['qrels_train'], data['qrels_dev']\n",
        "data_processor.print_samples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CLVHLUidFD4",
        "outputId": "d6c0255a-0683-4c82-8aea-37d25831cc3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passages:\n",
            "0: The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\n",
            "1: The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\n",
            "2: Essay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.\n",
            "3: The Manhattan Project was the name for a project conducted during World War II, to develop the first atomic bomb. It refers specifically to the period of the project from 194 â¦ 2-1946 under the control of the U.S. Army Corps of Engineers, under the administration of General Leslie R. Groves.\n",
            "4: versions of each volume as well as complementary websites. The first websiteâThe Manhattan Project: An Interactive Historyâis available on the Office of History and Heritage Resources website, http://www.cfo. doe.gov/me70/history. The Office of History and Heritage Resources and the National Nuclear Security\n",
            "\n",
            "Train Queries:\n",
            "121352: define extreme\n",
            "634306: what does chattel mean on credit history\n",
            "920825: what was the great leap forward brainly\n",
            "510633: tattoo fixers how much does it cost\n",
            "737889: what is decentralization process.\n",
            "\n",
            "Dev Queries:\n",
            "1048585: what is paula deen's brother\n",
            "2:  Androgen receptor define\n",
            "524332: treating tension headaches without medication\n",
            "1048642: what is paranoid sc\n",
            "524447: treatment of varicose veins in legs\n",
            "\n",
            "Train Qrels:\n",
            "1185869: ['0']\n",
            "1185868: ['16']\n",
            "597651: ['49']\n",
            "403613: ['60']\n",
            "1183785: ['389']\n",
            "\n",
            "Dev Qrels:\n",
            "300674: ['7067032']\n",
            "125705: ['7067056']\n",
            "94798: ['7067181']\n",
            "9083: ['7067274']\n",
            "174249: ['7067348']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    - Initialize the model(Contriever)\n",
        "'''\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using device', device)\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
        "# model = AutoModel.from_pretrained('facebook/contriever-msmarco').to(device)\n",
        "model = None\n",
        "tokenizer = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOgThhaNdJkN",
        "outputId": "1f52eafe-098a-4efd-a5f9-eb02ecedb34a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    - Load/Save the embeddings\n",
        "'''\n",
        "embedding_processor = EmbeddingProcessor(data_processor = data_processor, model = model, tokenizer = tokenizer, emb_root_dir = '../embeddings', batch_size = 128, device = device)\n",
        "# emb_dim = embedding_processor.get_emb_dim()"
      ],
      "metadata": {
        "id": "7ghWzaRhc53c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    - Train the Vector Quantizer\n",
        "    - Vector quantize the embeddings & Get the code indices\n",
        "'''\n",
        "quantizer = Quantize(dim = 6, num_clusters = 10).to(device = device)\n",
        "vq_hanlder = VQHandler(embedding_processor = embedding_processor, quantizer = quantizer, num_chunks = 128, device = device)\n",
        "quantizer = vq_hanlder.train()\n",
        "\n",
        "# Get the code indices for each passage in development set\n",
        "# These code indices are used to build the inverted index\n",
        "# code_indices = vq_hanlder.inference(type = 'passage', mode = 'dev')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YoXF50XdMLl",
        "outputId": "e69b685e-a355-4f08-92cb-336b2cca152b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asdflkasd;la\n",
            "../embeddings/train/passage_embeddings.pt\n",
            "Loading cached embeddings & ids...\n",
            "asdflkasd;la\n",
            "../embeddings/dev/passage_embeddings.pt\n",
            "Loading cached embeddings & ids...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training codebook vectors: 100%|██████████| 1859/1859 [00:02<00:00, 877.83it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_indices = vq_hanlder.inference(type = 'passage', mode = 'dev').cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiqQFmA1wpO2",
        "outputId": "1632698f-ffc1-41b0-c62b-b9635a2a1f6e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vector quantizing...: 100%|██████████| 15/15 [00:00<00:00, 685.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(code_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbJ_yXah8pKe",
        "outputId": "8d26eed1-d573-4b46-e1bc-9a42364150d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9 7 3 ... 8 3 4]\n",
            " [7 3 2 ... 8 6 9]\n",
            " [0 7 4 ... 8 3 4]\n",
            " ...\n",
            " [3 7 6 ... 8 4 1]\n",
            " [4 7 1 ... 8 1 2]\n",
            " [1 3 1 ... 8 1 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(code_indices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVYcfu2sxVGY",
        "outputId": "4334a635-f78b-4dc0-dec6-75c7bd64ac60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7433, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class InvertedIndexHandler:\n",
        "    def __init__(self, embedding_processor):\n",
        "        self.embedding_processor = embedding_processor\n",
        "        self.train_mapppings = self.embedding_processor.load_or_save_embeddings(mode = 'train')['mappings']\n",
        "        self.dev_mappings = self.embedding_processor.load_or_save_embeddings(mode = 'dev')['mappings']\n",
        "\n",
        "        # self.train_passage_ids = train_mapppings['passage_ids']\n",
        "        # self.dev_passage_ids = dev_mappings['passage_ids']\n",
        "        self.passage_ids = None\n",
        "        self.optimized_index = None\n",
        "        return\n",
        "\n",
        "    def create_inverted_index(self, code_indices, mode = 'dev'):\n",
        "        self.passage_ids = self.dev_mappings['passage_ids']\n",
        "        if mode == 'train':\n",
        "            self.passage_ids = self.train_mapppings['passage_ids']\n",
        "        elif mode != 'dev':\n",
        "            raise NotImplementedError(f\"Inverted index for {mode} not implemented!\")\n",
        "\n",
        "        inverted_index = defaultdict(list)\n",
        "        num_passages = len(self.passage_ids)\n",
        "\n",
        "        rows, cols, data = [], [], []\n",
        "        vocab_size = 10\n",
        "\n",
        "        for i, codes in enumerate(tqdm(code_indices, desc=\"Building passage matrix\")):\n",
        "            weights = Counter(codes)\n",
        "            for code, freq in weights.items():\n",
        "                rows.append(i)\n",
        "                # rows.append(passage_ids[i])\n",
        "                cols.append(code)\n",
        "                data.append(freq)\n",
        "\n",
        "        self.optimized_index = csr_matrix((data, (rows, cols)), shape=(len(code_indices), vocab_size), dtype=np.float32)\n",
        "        return self.optimized_index\n",
        "\n",
        "        # for i in tqdm(range(0, num_passages), desc = \"Building inverted index\"):\n",
        "        #     code_index_list = code_indices[i].tolist()\n",
        "        #     weights = Counter(code_index_list)\n",
        "        #     for code_index in list(set(code_index_list)):\n",
        "        #         inverted_index[int(code_index)].append((self.passage_ids[i], float(weights[code_index])))  # Ensure integer keys\n",
        "\n",
        "        # # Sort postings lists by weight for each term\n",
        "        # for idx in inverted_index:\n",
        "        #     inverted_index[idx] = sorted(inverted_index[idx], key = lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "        # # Convert to more efficient data structure\n",
        "        # self.optimized_index = {\n",
        "        #     idx: (\n",
        "        #         np.array([passage_id for passage_id, _ in postings], dtype = np.int32),\n",
        "        #         np.array([weight for _, weight in postings], dtype = np.float32)\n",
        "        #     )\n",
        "        #     for idx, postings in inverted_index.items()\n",
        "        # }\n",
        "\n",
        "        # return self.optimized_index\n",
        "\n",
        "    # Optimized search function for sparse retrieval using the inverted index\n",
        "    def search_inverted_index(self, query_matrix, query_ids):\n",
        "    # def search_inverted_index(self, query_code_index_list):\n",
        "        # scores = defaultdict(float)\n",
        "        # seen_passages = set()\n",
        "\n",
        "        # # Process each query term\n",
        "        # weights = Counter(query_code_index_list)\n",
        "        # query_code_index_list = list(set(query_code_index_list))\n",
        "        # for code_index in query_code_index_list:\n",
        "        #     if code_index not in self.optimized_index:\n",
        "        #         # print('Unexpected!!!')\n",
        "        #         continue\n",
        "\n",
        "        #     passage_ids, passage_weights = self.optimized_index[code_index]\n",
        "        #     query_weight = weights[code_index]\n",
        "\n",
        "        #     # Only process top documents per term\n",
        "        #     for passage_id, passage_weight in zip(passage_ids, passage_weights):\n",
        "        #         scores[passage_id] += query_weight * passage_weight\n",
        "        #         seen_passages.add(passage_id)\n",
        "\n",
        "        # # Use numpy for final scoring\n",
        "        # if seen_passages:\n",
        "        #     passage_ids = np.array(list(seen_passages))\n",
        "        #     passage_scores = np.array([scores[passage_id] for passage_id in passage_ids])\n",
        "\n",
        "        #     # Get top 1000 results efficiently\n",
        "        #     top_k = min(1000, len(passage_scores))\n",
        "        #     top_indices = np.argpartition(passage_scores, -top_k)[-top_k:]\n",
        "        #     top_indices = top_indices[np.argsort(-passage_scores[top_indices])]\n",
        "\n",
        "        #     return [(passage_ids[i], passage_scores[i]) for i in top_indices]\n",
        "\n",
        "        # return []\n",
        "        num_queries = query_matrix.shape[0]\n",
        "\n",
        "        all_results = {}\n",
        "        for start in tqdm(range(0, num_queries, 128), desc=\"Scoring queries in chunks\"):\n",
        "            end = min(start + 128, num_queries)\n",
        "            query_chunk = query_matrix[start:end]\n",
        "            scores_chunk = query_chunk @ self.optimized_index.T  # shape: [batch_size, num_passages]\n",
        "\n",
        "            topk_idx = np.argpartition(-scores_chunk, 1000, axis=1)[:, :1000]\n",
        "            for i in range(scores_chunk.shape[0]):\n",
        "                passage_scores = scores_chunk[i]\n",
        "                top_i = topk_idx[i]\n",
        "                top_indices = top_i[np.argsort(-passage_scores[top_i])]\n",
        "\n",
        "                all_results[query_ids[start + i]] = [(self.passage_ids[t], passage_scores[t]) for t in top_indices]\n",
        "\n",
        "        return all_results"
      ],
      "metadata": {
        "id": "0AsypeI1xYy4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    - Create the inverted index with the vector quantized indices\n",
        "'''\n",
        "inverted_index_handler = InvertedIndexHandler(embedding_processor = embedding_processor)\n",
        "\n",
        "# Code indices of the passage set that you are working on\n",
        "# Changes based on the mode (dev/train)\n",
        "obj = inverted_index_handler.create_inverted_index(code_indices = code_indices, mode = 'dev')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9yoEJzNqxvm7",
        "outputId": "62933e69-5be4-4d82-d96a-8166f01e9a14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asdflkasd;la\n",
            "../embeddings/train/passage_embeddings.pt\n",
            "Loading cached embeddings & ids...\n",
            "asdflkasd;la\n",
            "../embeddings/dev/passage_embeddings.pt\n",
            "Loading cached embeddings & ids...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building passage matrix: 100%|██████████| 7433/7433 [00:00<00:00, 24249.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# all_passage_ids = np.concatenate([postings[0] for postings in inverted_index_handler.optimized_index.values()])\n",
        "# num_unique_passages = len(np.unique(all_passage_ids))\n",
        "# print(\"Unique passage IDs:\", num_unique_passages)\n",
        "inverted_index_handler.optimized_index.shape\n",
        "# len(inverted_index_handler.optimized_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAo5oUlD2E8o",
        "outputId": "6ad452cd-62d8-4b65-9b65-23a1dce5e4db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7433, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from ranx import Qrels, Run, evaluate\n",
        "\n",
        "class MetricsGenerator:\n",
        "    def __init__(self, inverted_index_handler, embedding_processor, qrels):\n",
        "        self.inverted_index_handler = inverted_index_handler\n",
        "\n",
        "        self.embedding_processor = embedding_processor\n",
        "        train_mapppings = self.embedding_processor.load_or_save_embeddings(mode = 'train')['mappings']\n",
        "        dev_mappings = self.embedding_processor.load_or_save_embeddings(mode = 'dev')['mappings']\n",
        "\n",
        "        self.train_query_ids = train_mapppings['query_ids']\n",
        "        self.dev_query_ids = dev_mappings['query_ids']\n",
        "\n",
        "        self.train_qrels = qrels['train']\n",
        "        self.dev_qrels = qrels['dev']\n",
        "        self.query_matrix = None\n",
        "        return\n",
        "\n",
        "    def build_query_matrix(self, query_code_indices):\n",
        "      vocab_size = 10\n",
        "      self.query_matrix = np.zeros((len(query_code_indices), vocab_size), dtype=np.float32)\n",
        "\n",
        "      for i, codes in enumerate(query_code_indices):\n",
        "          weights = Counter(codes)\n",
        "          for code, freq in weights.items():\n",
        "              self.query_matrix[i, code] = freq\n",
        "\n",
        "      return self.query_matrix\n",
        "\n",
        "    def batch_score_queries(self, top_k = 1000):\n",
        "      scores_matrix = self.query_matrix @ self.inverted_index.T  # shape: [num_queries, num_passages]\n",
        "      top_k_indices = np.argpartition(-scores_matrix, top_k, axis=1)[:, :top_k]\n",
        "\n",
        "      results = {}\n",
        "      for i in range(scores_matrix.shape[0]):\n",
        "          row = scores_matrix[i]\n",
        "          top_idx = top_k_indices[i]\n",
        "          sorted_idx = top_idx[np.argsort(-row[top_idx])]\n",
        "          results.append(list(zip(sorted_idx, row[sorted_idx])))\n",
        "\n",
        "      return results\n",
        "\n",
        "    def get_metrics(self, code_indices, mode = 'dev', batch_size = 128):\n",
        "        query_ids = self.dev_query_ids\n",
        "        q_rels = self.dev_qrels\n",
        "        if mode == 'train':\n",
        "            query_ids = self.train_query_ids\n",
        "            qrels = self.train_qrels\n",
        "        elif mode != 'dev':\n",
        "            raise NotImplementedError(f\"Metrics calculator not implemented for {mode}!\")\n",
        "\n",
        "        # all_results = {}\n",
        "        # num_queries = len(query_ids)\n",
        "        # for i in tqdm(range(0, num_queries), desc = \"Evaluating queries\"):\n",
        "        #     code_index_list = code_indices[i].tolist()\n",
        "        #     search_results = self.inverted_index_handler.search_inverted_index(code_index_list)\n",
        "        #     all_results[query_ids[i]] = search_results\n",
        "\n",
        "        all_results = self.inverted_index_handler.search_inverted_index(self.query_matrix, query_ids)\n",
        "\n",
        "        # Create rank_eval Run and Qrels objects\n",
        "        run_dict = {}\n",
        "        for qid, results in all_results.items():\n",
        "            run_dict[qid] = {\n",
        "                str(passage_id): float(score)\n",
        "                for passage_id, score in results\n",
        "            }\n",
        "        run = Run(run_dict)\n",
        "\n",
        "        qrels_dict = {\n",
        "            qid: {str(passage_id): 1 for passage_id in q_rels[qid]}\n",
        "            for qid in q_rels\n",
        "        }\n",
        "        qrels = Qrels(qrels_dict)\n",
        "\n",
        "        # Evaluate using rankx\n",
        "        metrics = [\"ndcg@10\", \"ndcg@100\", \"ndcg@1000\", \"recall@10\", \"recall@100\", \"recall@1000\", \"mrr@10\"]\n",
        "        results = evaluate(qrels, run, metrics)\n",
        "\n",
        "        return (\n",
        "            results[\"mrr@10\"],\n",
        "            {\n",
        "                '10': results[\"ndcg@10\"],\n",
        "                '100': results[\"ndcg@100\"],\n",
        "                '1000': results[\"ndcg@1000\"]\n",
        "            },\n",
        "            {\n",
        "                '10': results[\"recall@10\"],\n",
        "                '100': results[\"recall@100\"],\n",
        "                '1000': results[\"recall@1000\"]\n",
        "            }\n",
        "        )"
      ],
      "metadata": {
        "id": "fnSU19GhxxHQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    - Generate Metrics using the inverted index built\n",
        "'''\n",
        "\n",
        "# Pass qrels to calculate the metrics\n",
        "qrels = {\n",
        "    'train': qrels_train,\n",
        "    'dev': qrels_dev\n",
        "}\n",
        "\n",
        "# Get the code indices for each query in the development set\n",
        "# These code indices are used to calculate the scores and metrics\n",
        "query_code_indices = vq_hanlder.inference(type = 'query', mode = 'dev')\n",
        "\n",
        "metrics_generator = MetricsGenerator(inverted_index_handler = inverted_index_handler, embedding_processor = embedding_processor, qrels = qrels)\n",
        "metrics_generator.build_query_matrix(query_code_indices)\n",
        "results = metrics_generator.get_metrics(code_indices = query_code_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlsHZUxzyQLe",
        "outputId": "035c1d73-62f2-4d29-8cc1-893f3dde01af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vector quantizing...: 100%|██████████| 14/14 [00:00<00:00, 1017.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asdflkasd;la\n",
            "../embeddings/train/passage_embeddings.pt\n",
            "Loading cached embeddings & ids...\n",
            "asdflkasd;la\n",
            "../embeddings/dev/passage_embeddings.pt\n",
            "Loading cached embeddings & ids...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring queries in chunks: 100%|██████████| 55/55 [00:02<00:00, 19.16it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/ranx/metrics/ndcg.py:72: NumbaTypeSafetyWarning: unsafe cast from uint64 to int64. Precision may be lost.\n",
            "  scores[i] = _ndcg(qrels[i], run[i], k, rel_lvl, jarvelin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_code_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td-tcFfK_gYm",
        "outputId": "36e5d97f-38cc-4f71-f89a-eee1326ce013"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6, 1, 4,  ..., 8, 3, 2],\n",
              "        [7, 4, 4,  ..., 8, 4, 7],\n",
              "        [3, 0, 2,  ..., 8, 1, 2],\n",
              "        ...,\n",
              "        [7, 1, 4,  ..., 8, 0, 7],\n",
              "        [7, 4, 0,  ..., 8, 0, 0],\n",
              "        [0, 1, 7,  ..., 8, 0, 4]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_code_indices.shape, code_indices.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azN_oMZH7cPh",
        "outputId": "b35aa7e9-d851-4b5a-8bda-96b77bee1fa3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6980, 128]), (7433, 128))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCgjB7HOyc-y",
        "outputId": "d42b3411-b5d0-4d55-db37-0df96425a61f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.0004196229590212398),\n",
              " {'10': np.float64(0.000595835526254673),\n",
              "  '100': np.float64(0.0029155282810198815),\n",
              "  '1000': np.float64(0.01688858877149606)},\n",
              " {'10': np.float64(0.001325214899713467),\n",
              "  '100': np.float64(0.013861031518624643),\n",
              "  '1000': np.float64(0.13527936962750717)})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du9hdsnlnCkc",
        "outputId": "0ffba407-d99c-4906-b1d5-f7865cc8e16c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.021673773138672848),\n",
              " {'10': np.float64(0.02566012687020493),\n",
              "  '100': np.float64(0.037404539590592756),\n",
              "  '1000': np.float64(0.05318459512457225)},\n",
              " {'10': np.float64(0.040568290353390636),\n",
              "  '100': np.float64(0.1004297994269341),\n",
              "  '1000': np.float64(0.23006208213944604)})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRICSwiMyZKY",
        "outputId": "c4f7eed2-cdbc-4e59-e90a-2784a7d27469"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0004196229590212398,\n",
              " {'10': 0.0006232282141076039,\n",
              "  '100': 0.0028432873958526925,\n",
              "  '1000': 0.01679376817421632},\n",
              " {'10': 0.0013610315186246419,\n",
              "  '100': 0.013347659980897802,\n",
              "  '1000': 0.1346585482330468})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mj9ZzB46hBk",
        "outputId": "4907dad5-7b2a-4cbc-a65e-3375fca85396"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0004196229590212398,\n",
              " {'10': 0.0006232282141076039,\n",
              "  '100': 0.0028432873958526925,\n",
              "  '1000': 0.01679376817421632},\n",
              " {'10': 0.0013610315186246419,\n",
              "  '100': 0.013347659980897802,\n",
              "  '1000': 0.1346585482330468})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikdWgvVF_JfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}